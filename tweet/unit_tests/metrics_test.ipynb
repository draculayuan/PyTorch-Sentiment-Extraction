{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from data import TweetDataset, tweet_collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(output, mask, ori_tok, sel_tok, sent):\n",
    "    def jaccard(str1, str2): \n",
    "        a = set(str1.lower().split()) \n",
    "        b = set(str2.lower().split())\n",
    "        c = a.intersection(b)\n",
    "        return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "    # For each record\n",
    "    jac = 0.0\n",
    "    pred_toks = []\n",
    "    for idx in range(output.size(0)):\n",
    "        # Step 1, extract pred_tok from origin_tok\n",
    "        temp = torch.argmax(output[idx], dim=1)\n",
    "        temp[mask[idx]==0] = 0\n",
    "        start = 0\n",
    "        end = temp.size(0) - 1\n",
    "        while start <= end and temp[start].item() != 1:\n",
    "            start += 1\n",
    "        while start <= end and temp[end].item() != 1:\n",
    "            end -= 1\n",
    "        # minus the offset\n",
    "        start = max(0, start - 1)\n",
    "        end = min(max(0, end - 1), len(ori_tok[idx])-1)\n",
    "        if sent[idx].item() == 0 or len(ori_tok) <= 3:\n",
    "            pred_tok = ori_tok[idx]\n",
    "        else:\n",
    "            pred_tok = ori_tok[idx][start:end+1]\n",
    "        # Step 2, cal jaccard\n",
    "        jac += jaccard(' '.join(pred_tok), ' '.join(sel_tok[idx]))\n",
    "        pred_toks.append(pred_tok)\n",
    "    return jac / output.size(0), pred_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_data = TweetDataset('/home/liu/DL_workstation/tweet-sent/data/train.csv',\n",
    "                         64)\n",
    "loader = DataLoader(train_data, 32, collate_fn = tweet_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch_idx, (text, mask, sel_label, label, ori_tok, sel_tok) in enumerate(loader):\n",
    "    text = text.cuda()\n",
    "    mask = mask.cuda()\n",
    "    out = model(text, mask)\n",
    "    _, _ = performance(out, mask, ori_tok, sel_tok, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensetime",
   "language": "python",
   "name": "sensetime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
